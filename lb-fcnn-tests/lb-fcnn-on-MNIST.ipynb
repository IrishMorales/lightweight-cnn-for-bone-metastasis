{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lightweight LB-FCNN on MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchstat in c:\\users\\irish\\anaconda3\\envs\\conv_env\\lib\\site-packages (0.0.7)\n",
      "Requirement already satisfied: numpy in c:\\users\\irish\\anaconda3\\envs\\conv_env\\lib\\site-packages (from torchstat) (1.23.5)\n",
      "Requirement already satisfied: pandas in c:\\users\\irish\\anaconda3\\envs\\conv_env\\lib\\site-packages (from torchstat) (1.5.3)\n",
      "Requirement already satisfied: torch in c:\\users\\irish\\anaconda3\\envs\\conv_env\\lib\\site-packages (from torchstat) (1.13.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\irish\\anaconda3\\envs\\conv_env\\lib\\site-packages (from pandas->torchstat) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\irish\\anaconda3\\envs\\conv_env\\lib\\site-packages (from pandas->torchstat) (2022.7)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\irish\\anaconda3\\envs\\conv_env\\lib\\site-packages (from torch->torchstat) (4.4.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\irish\\anaconda3\\envs\\conv_env\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->torchstat) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Irish\\anaconda3\\envs\\conv_env\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: [WinError 127] The specified procedure could not be found\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from torchstat import stat\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Variables & Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2991a805cd0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set seed for random number generation to create reproducible results\n",
    "random_seed = 5\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.MNIST(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.Grayscale(3), # convert from 1 grayscale channel to 3 RGB channels\n",
    "        transforms.ToTensor()] \n",
    "    )\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root='data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.Grayscale(3), # convert from 1 grayscale channel to 3 RGB channels\n",
    "        transforms.ToTensor()] \n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model hyperparameters; epochs & batch size from Magboo & Abu\n",
    "epochs = 3 # 100\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image channels - 3 for R, G, B feature maps\n",
    "channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depthwise Separable Convolution\n",
    "class DSConv(nn.Module):\n",
    "    # Define layers\n",
    "    def __init__(self, kernel_size):\n",
    "        super(DSConv, self).__init__()\n",
    "        self.depthwise_conv = nn.Conv2d(in_channels = channels, out_channels = channels, padding = 'same',\n",
    "                                        kernel_size = kernel_size, bias = False, groups = channels)\n",
    "        self.pointwise_conv = nn.Conv2d(in_channels = channels, out_channels = 1, \n",
    "                                        kernel_size = 1, bias = False)\n",
    "\n",
    "    # Apply layers\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.depthwise_conv(x))\n",
    "        x = F.leaky_relu(self.pointwise_conv(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiscale Depthwise Separable Convolution module\n",
    "class MDSConv(nn.Module):\n",
    "    # Define layers\n",
    "    def __init__(self):\n",
    "        super(MDSConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels = channels, out_channels = channels, kernel_size = 1, bias = False)\n",
    "        self.norm1 = nn.BatchNorm2d(num_features = channels)\n",
    "        self.norm2 = nn.BatchNorm2d(num_features = 1)\n",
    "        self.ds_conv1 = DSConv(kernel_size = 3)\n",
    "        self.ds_conv2 = DSConv(kernel_size = 5)\n",
    "        self.ds_conv3 = DSConv(kernel_size = 7)\n",
    "        \n",
    "    # Apply layers\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.conv(x))\n",
    "        x = self.norm1(x)\n",
    "        \n",
    "        # Depthwise separable convolution with 3x3 kernel\n",
    "        x1 = self.ds_conv1(x)\n",
    "        x1 = self.norm2(x1)\n",
    "        \n",
    "        # Depthwise separable convolution with 5x5 kernel\n",
    "        x2 = self.ds_conv2(x)\n",
    "        x2 = self.norm2(x2)\n",
    "        \n",
    "        # Depthwise separable convolution with 7x7 kernel\n",
    "        x3 = self.ds_conv3(x)\n",
    "        x3 = self.norm2(x3)\n",
    "        \n",
    "        x = torch.concat((x1, x2, x3), dim = 1)\n",
    "        x = self.norm1(x)\n",
    "        x = F.leaky_relu(self.conv(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual Connection module\n",
    "class ResConnection(nn.Module):\n",
    "    # Define layers\n",
    "    def __init__(self):\n",
    "        super(ResConnection, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels = channels, out_channels = channels, kernel_size = 1, bias = False)\n",
    "        self.norm = nn.BatchNorm2d(num_features = channels)\n",
    "\n",
    "    # Apply layers\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.conv(x))\n",
    "        x = self.norm(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The main building block of LB-FCNN light architecture\n",
    "class LBFCNNLightBlock(nn.Module):\n",
    "    # Define layers\n",
    "    def __init__(self):\n",
    "        super(LBFCNNLightBlock, self).__init__()\n",
    "        self.mdsc = MDSConv()\n",
    "        self.rc = ResConnection()\n",
    "        self.conv = nn.Conv2d(in_channels = channels, out_channels = channels, kernel_size = 1, bias = False)\n",
    "        self.norm = nn.BatchNorm2d(num_features = channels)\n",
    "        \n",
    "    # Apply layers\n",
    "    def forward(self, x):\n",
    "        x_mdsc = self.mdsc(x)\n",
    "        x_rc = self.rc(x)\n",
    "        x = torch.add(x_mdsc, x_rc)\n",
    "        x = F.leaky_relu(self.conv(x))\n",
    "        x = self.norm(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LB-FCNN light model\n",
    "class LBFCNNLight(nn.Module):\n",
    "    # Define layers\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mdsc = MDSConv()\n",
    "        self.lbfcnn_block = LBFCNNLightBlock()\n",
    "        self.pool = nn.Conv2d(in_channels = channels, out_channels = channels, \n",
    "                              kernel_size = 2, stride = 2, bias = False)\n",
    "        self.fc = nn.Linear(in_features = channels, out_features = 10)\n",
    "        # TODO: Fix pool; paper says kernel size=3, but kernel=3 results in tensor shapes that don't match the paper diagram\n",
    "        # Some other value somewhere must be excess by 1\n",
    "        \n",
    "        # TODO: Fix feature maps here don't match feature maps in paper diagram\n",
    "        \n",
    "    # Apply layers\n",
    "    def forward(self, x):\n",
    "        x = self.mdsc(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.lbfcnn_block(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.lbfcnn_block(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.lbfcnn_block(x)\n",
    "        x = self.pool(x)\n",
    "        x = F.adaptive_avg_pool2d(x, (1, 1))\n",
    "        x = torch.flatten(input = x, start_dim = 1)\n",
    "        x = self.fc(x)\n",
    "        x = F.softmax(input = x, dim = 1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing torch operations on cpu device\n"
     ]
    }
   ],
   "source": [
    "# Allocate tensors to the device used for computation\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Performing torch operations on {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 3, 646, 220]               9\n",
      "       BatchNorm2d-2          [-1, 3, 646, 220]               6\n",
      "            Conv2d-3          [-1, 3, 646, 220]              27\n",
      "            Conv2d-4          [-1, 1, 646, 220]               3\n",
      "            DSConv-5          [-1, 1, 646, 220]               0\n",
      "       BatchNorm2d-6          [-1, 1, 646, 220]               2\n",
      "            Conv2d-7          [-1, 3, 646, 220]              75\n",
      "            Conv2d-8          [-1, 1, 646, 220]               3\n",
      "            DSConv-9          [-1, 1, 646, 220]               0\n",
      "      BatchNorm2d-10          [-1, 1, 646, 220]               2\n",
      "           Conv2d-11          [-1, 3, 646, 220]             147\n",
      "           Conv2d-12          [-1, 1, 646, 220]               3\n",
      "           DSConv-13          [-1, 1, 646, 220]               0\n",
      "      BatchNorm2d-14          [-1, 1, 646, 220]               2\n",
      "      BatchNorm2d-15          [-1, 3, 646, 220]               6\n",
      "           Conv2d-16          [-1, 3, 646, 220]               9\n",
      "          MDSConv-17          [-1, 3, 646, 220]               0\n",
      "           Conv2d-18          [-1, 3, 323, 110]              36\n",
      "           Conv2d-19          [-1, 3, 323, 110]               9\n",
      "      BatchNorm2d-20          [-1, 3, 323, 110]               6\n",
      "           Conv2d-21          [-1, 3, 323, 110]              27\n",
      "           Conv2d-22          [-1, 1, 323, 110]               3\n",
      "           DSConv-23          [-1, 1, 323, 110]               0\n",
      "      BatchNorm2d-24          [-1, 1, 323, 110]               2\n",
      "           Conv2d-25          [-1, 3, 323, 110]              75\n",
      "           Conv2d-26          [-1, 1, 323, 110]               3\n",
      "           DSConv-27          [-1, 1, 323, 110]               0\n",
      "      BatchNorm2d-28          [-1, 1, 323, 110]               2\n",
      "           Conv2d-29          [-1, 3, 323, 110]             147\n",
      "           Conv2d-30          [-1, 1, 323, 110]               3\n",
      "           DSConv-31          [-1, 1, 323, 110]               0\n",
      "      BatchNorm2d-32          [-1, 1, 323, 110]               2\n",
      "      BatchNorm2d-33          [-1, 3, 323, 110]               6\n",
      "           Conv2d-34          [-1, 3, 323, 110]               9\n",
      "          MDSConv-35          [-1, 3, 323, 110]               0\n",
      "           Conv2d-36          [-1, 3, 323, 110]               9\n",
      "      BatchNorm2d-37          [-1, 3, 323, 110]               6\n",
      "    ResConnection-38          [-1, 3, 323, 110]               0\n",
      "           Conv2d-39          [-1, 3, 323, 110]               9\n",
      "      BatchNorm2d-40          [-1, 3, 323, 110]               6\n",
      " LBFCNNLightBlock-41          [-1, 3, 323, 110]               0\n",
      "           Conv2d-42           [-1, 3, 161, 55]              36\n",
      "           Conv2d-43           [-1, 3, 161, 55]               9\n",
      "      BatchNorm2d-44           [-1, 3, 161, 55]               6\n",
      "           Conv2d-45           [-1, 3, 161, 55]              27\n",
      "           Conv2d-46           [-1, 1, 161, 55]               3\n",
      "           DSConv-47           [-1, 1, 161, 55]               0\n",
      "      BatchNorm2d-48           [-1, 1, 161, 55]               2\n",
      "           Conv2d-49           [-1, 3, 161, 55]              75\n",
      "           Conv2d-50           [-1, 1, 161, 55]               3\n",
      "           DSConv-51           [-1, 1, 161, 55]               0\n",
      "      BatchNorm2d-52           [-1, 1, 161, 55]               2\n",
      "           Conv2d-53           [-1, 3, 161, 55]             147\n",
      "           Conv2d-54           [-1, 1, 161, 55]               3\n",
      "           DSConv-55           [-1, 1, 161, 55]               0\n",
      "      BatchNorm2d-56           [-1, 1, 161, 55]               2\n",
      "      BatchNorm2d-57           [-1, 3, 161, 55]               6\n",
      "           Conv2d-58           [-1, 3, 161, 55]               9\n",
      "          MDSConv-59           [-1, 3, 161, 55]               0\n",
      "           Conv2d-60           [-1, 3, 161, 55]               9\n",
      "      BatchNorm2d-61           [-1, 3, 161, 55]               6\n",
      "    ResConnection-62           [-1, 3, 161, 55]               0\n",
      "           Conv2d-63           [-1, 3, 161, 55]               9\n",
      "      BatchNorm2d-64           [-1, 3, 161, 55]               6\n",
      " LBFCNNLightBlock-65           [-1, 3, 161, 55]               0\n",
      "           Conv2d-66            [-1, 3, 80, 27]              36\n",
      "           Conv2d-67            [-1, 3, 80, 27]               9\n",
      "      BatchNorm2d-68            [-1, 3, 80, 27]               6\n",
      "           Conv2d-69            [-1, 3, 80, 27]              27\n",
      "           Conv2d-70            [-1, 1, 80, 27]               3\n",
      "           DSConv-71            [-1, 1, 80, 27]               0\n",
      "      BatchNorm2d-72            [-1, 1, 80, 27]               2\n",
      "           Conv2d-73            [-1, 3, 80, 27]              75\n",
      "           Conv2d-74            [-1, 1, 80, 27]               3\n",
      "           DSConv-75            [-1, 1, 80, 27]               0\n",
      "      BatchNorm2d-76            [-1, 1, 80, 27]               2\n",
      "           Conv2d-77            [-1, 3, 80, 27]             147\n",
      "           Conv2d-78            [-1, 1, 80, 27]               3\n",
      "           DSConv-79            [-1, 1, 80, 27]               0\n",
      "      BatchNorm2d-80            [-1, 1, 80, 27]               2\n",
      "      BatchNorm2d-81            [-1, 3, 80, 27]               6\n",
      "           Conv2d-82            [-1, 3, 80, 27]               9\n",
      "          MDSConv-83            [-1, 3, 80, 27]               0\n",
      "           Conv2d-84            [-1, 3, 80, 27]               9\n",
      "      BatchNorm2d-85            [-1, 3, 80, 27]               6\n",
      "    ResConnection-86            [-1, 3, 80, 27]               0\n",
      "           Conv2d-87            [-1, 3, 80, 27]               9\n",
      "      BatchNorm2d-88            [-1, 3, 80, 27]               6\n",
      " LBFCNNLightBlock-89            [-1, 3, 80, 27]               0\n",
      "           Conv2d-90            [-1, 3, 40, 13]              36\n",
      "           Linear-91                   [-1, 10]              40\n",
      "================================================================\n",
      "Total params: 1,450\n",
      "Trainable params: 1,450\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.63\n",
      "Forward/backward pass size (MB): 54.97\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 56.60\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Inspect model shapes per layer\n",
    "model = LBFCNNLight().to(device)\n",
    "summary(model, (3, 646, 220))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation metrics\n",
    "results_accuracy = []\n",
    "results_precision = []\n",
    "results_sensitivity = []\n",
    "results_specificity = []\n",
    "results_f1 = []\n",
    "train_losses = []\n",
    "test_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 42\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m phase \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m# Backpropagation\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad() \u001b[38;5;66;03m# Reset gradients from previous passes\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Compute gradients using derivative of loss\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep() \u001b[38;5;66;03m# Update values using gradients\u001b[39;00m\n\u001b[0;32m     45\u001b[0m total_batch_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;66;03m# Increment number of finished batches\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\conv_env\\lib\\site-packages\\torch\\_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    480\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    481\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    486\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    487\u001b[0m     )\n\u001b[1;32m--> 488\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\conv_env\\lib\\site-packages\\torch\\autograd\\__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train model for k folds, with e epochs each \n",
    "trainloader = DataLoader(training_data, batch_size=batch_size)\n",
    "testloader = DataLoader(test_data, batch_size=batch_size)\n",
    "    \n",
    "train_losses.append([])\n",
    "test_losses.append([])\n",
    "    \n",
    "# Instantiate model\n",
    "model = LBFCNNLight().to(device)\n",
    "    \n",
    "# Define criterion (function used to compute loss) and optimizer for model\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "# ---------- Run for x epochs on training set and test set ----------\n",
    "for epoch in range(epochs):\n",
    "        \n",
    "    for phase in ['train', 'test']:\n",
    "        if phase == 'train':\n",
    "            model.train()\n",
    "            dataloader = trainloader\n",
    "        else:\n",
    "            model.eval()\n",
    "            dataloader = testloader\n",
    "            \n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        total_batch_count = 0\n",
    "\n",
    "        for inputs, labels in dataloader:\n",
    "            # Get the inputs; data is a list of [images, labels]\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            if phase == 'train':\n",
    "                # Backpropagation\n",
    "                optimizer.zero_grad() # Reset gradients from previous passes\n",
    "                loss.backward() # Compute gradients using derivative of loss\n",
    "                optimizer.step() # Update values using gradients\n",
    "                \n",
    "            total_batch_count += 1 # Increment number of finished batches\n",
    "            running_loss += loss.item() # Add batch loss to current epoch loss\n",
    "\n",
    "        running_loss /= total_batch_count\n",
    "            \n",
    "        if phase == 'train':\n",
    "            train_losses[fold].append(running_loss)\n",
    "            print(f\"Epoch {epoch+1}/{epochs} Training Loss: {running_loss}\")\n",
    "        else:\n",
    "            test_losses[fold].append(running_loss)\n",
    "            print(f\"Epoch {epoch+1}/{epochs} Test Loss: {running_loss}\")\n",
    "                  \n",
    "# ---------- Get performance metrics for this fold ----------\n",
    "correct = 0\n",
    "incorrect = 0\n",
    "total = 0\n",
    "    \n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_index, batch_data in enumerate(testloader):\n",
    "        # Get the inputs; data is a list of [images, labels]\n",
    "        images, labels = batch_data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        predictions = model(images)\n",
    "\n",
    "        # Set total and correct\n",
    "        _, predicted = torch.max(input=predictions, dim=1) # Get list of predicted classes\n",
    "            \n",
    "        # Get how many classes there were in this batch\n",
    "        total += labels.size(0)\n",
    "            \n",
    "        # Get true positive, true negative, false positive, and false negative counts\n",
    "        for index in range(len(labels)):\n",
    "            correct = correct+1 if (predicted[index] == labels[index]) else correct\n",
    "            incorrect = incorrect+1 if (predicted[index] != labels[index]) else incorrect\n",
    "\n",
    "print(f\"correct: {correct}, incorrect: {incorrect}, total: {total}\")\n",
    "    \n",
    "# Get evaluation metrics\n",
    "accuracy = correct/total if total != 0 else 0\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "results_accuracy.append(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print tensor sizes per layer in model\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print optimizer's state_dict\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'weights/lbfcnn_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot train losses\n",
    "ax = plt.axes()\n",
    "for fold_losses in train_losses:\n",
    "    plt.plot(fold_losses)\n",
    "plt.title('Training Loss Evaluation per fold')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Magnitude')\n",
    "plt.legend(['Fold ' + str(x) for x in range(1, 11)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot test losses\n",
    "ax = plt.axes()\n",
    "for fold_losses in test_losses:\n",
    "    plt.plot(fold_losses)\n",
    "plt.title('Test Loss Evaluation per fold')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Magnitude')\n",
    "plt.legend(['Fold ' + str(x) for x in range(1, 11)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get performance metrics by calculcating average of metrics across all folds\n",
    "print(\"Final Performance Metrics\")\n",
    "print(f\"Accuracy: {np.mean(results_accuracy)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Predictions on Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_img_names = [\"0000-0-A.tif\", \"0163-0-P.tif\", \"0198-0-A.tif\"]\n",
    "sample_img_paths = [(data_dir + \"/\" + sample_img_names[i]) for i in range(len(sample_img_names))]\n",
    "sample_classes = [sample_img_names[i][5] for i in range(len(sample_img_names))]\n",
    "sample_ground_truths = [\"No Metastasis\" if sample_classes[i] == 0 else \"Metastasis\" for i in range(len(sample_img_names))]\n",
    "sample_imgs = [Image.open(img_path).convert('RGB') for img_path in sample_img_paths]\n",
    "sample_imgs_show = [Image.open(img_path) for img_path in sample_img_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_batch = torch.stack([preprocess(img).to(device) for img in sample_imgs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_preds= model(validation_batch).detach().cpu().data.numpy()\n",
    "sample_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, len(sample_imgs_show), figsize=(20, 5))\n",
    "for i, img in enumerate(sample_imgs_show):\n",
    "    ax = axs[i]\n",
    "    ax.axis('off')\n",
    "    ax.set_title(\"Prediction: {:.0f}% No Metastasis, {:.0f}% Metastasis \\n Ground Truth: {}\"\n",
    "                 .format(100*sample_preds[i,0], 100*sample_preds[i,1], sample_ground_truths[i]))\n",
    "    ax.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# NOTE: Due to lack of library support for CUDA, this will error if using CUDA\n",
    "# Get computational complexity\n",
    "model = model.to(\"cpu\")\n",
    "stat(model, (3, 646, 220))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
