{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bone Metastasis Classification using MobileNet x Lightweight LB-FCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Irish\\anaconda3\\envs\\conv_env\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: [WinError 127] The specified procedure could not be found\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from torchstat import stat\n",
    "from torchsummary import summary\n",
    "# Imports from PyTorch source code for MobileNet v2\n",
    "from typing import Any, Callable, List, Optional\n",
    "from torch import nn, Tensor\n",
    "from torchvision.ops.misc import Conv2dNormActivation\n",
    "from torchvision.transforms._presets import ImageClassification\n",
    "from torchvision.utils import _log_api_usage_once\n",
    "from torchvision.models._api import Weights, WeightsEnum\n",
    "from torchvision.models._meta import _IMAGENET_CATEGORIES\n",
    "from torchvision.models._utils import _make_divisible, _ovewrite_named_param, handle_legacy_interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Variables & Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x25220445cd0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set seed for random number generation to create reproducible results\n",
    "random_seed = 5\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformations to apply to inputs\n",
    "preprocess = transforms.Compose([\n",
    "    # transforms.Resize(256),\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to get ground truth class of an image\n",
    "def get_img_labels(img_dir):\n",
    "    labels = ''\n",
    "    \n",
    "    for filename in os.listdir(img_dir):\n",
    "        # If image has no metastasis\n",
    "        if (filename[5] == '0'):\n",
    "            labels += filename + \",0\\n\"\n",
    "            \n",
    "        # If image has metastasis\n",
    "        else:\n",
    "            labels += filename + \",1\\n\"\n",
    "        \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = r\"../dataset-sample-flat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, img_dir, transform):\n",
    "        self.img_dir = img_dir\n",
    "        self.img_labels = pd.read_csv(StringIO(get_img_labels(img_dir)), sep=\",\", header=None)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Generate image filepath\n",
    "        filename = self.img_labels.iloc[idx, 0]\n",
    "        img_path = self.img_dir + \"/\" + filename\n",
    "        \n",
    "        # Read and transform image\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        image = self.transform(image)\n",
    "        \n",
    "        # Determine ground truth class (metastasis or no metastasis)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset and dataloader for training data\n",
    "dataset = CustomDataset(img_dir=data_dir, transform=preprocess)\n",
    "labels = list(dataset.img_labels.iloc[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model hyperparameters; epochs & batch size from Magboo & Abu\n",
    "k_folds = 3 # 10\n",
    "epochs = 2 # 100\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image channels - 3 for R, G, B feature maps\n",
    "channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depthwise Separable Convolution\n",
    "class DSConv(nn.Module):\n",
    "    # Define layers\n",
    "    def __init__(self, kernel_size):\n",
    "        super(DSConv, self).__init__()\n",
    "        self.depthwise_conv = nn.Conv2d(in_channels = channels, out_channels = channels, padding = 'same',\n",
    "                                        kernel_size = kernel_size, bias = False, groups = channels)\n",
    "        self.pointwise_conv = nn.Conv2d(in_channels = channels, out_channels = 1, \n",
    "                                        kernel_size = 1, bias = False)\n",
    "\n",
    "    # Apply layers\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.depthwise_conv(x))\n",
    "        x = F.leaky_relu(self.pointwise_conv(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiscale Depthwise Separable Convolution module\n",
    "class MDSConv(nn.Module):\n",
    "    # Define layers\n",
    "    def __init__(self, stride: int = 1):\n",
    "        super(MDSConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels = channels, out_channels = channels, kernel_size = 1, bias = False, stride = stride)\n",
    "        self.norm1 = nn.BatchNorm2d(num_features = channels)\n",
    "        self.norm2 = nn.BatchNorm2d(num_features = 1)\n",
    "        self.ds_conv1 = DSConv(kernel_size = 3)\n",
    "        self.ds_conv2 = DSConv(kernel_size = 5)\n",
    "        self.ds_conv3 = DSConv(kernel_size = 7)\n",
    "        \n",
    "    # Apply layers\n",
    "    def forward(self, x):\n",
    "        print(f\"MDSCONV START {x.shape} -------------------------------------------\")\n",
    "        x = F.leaky_relu(self.conv(x))\n",
    "        x = self.norm1(x)\n",
    "        \n",
    "        # Depthwise separable convolution with 3x3 kernel\n",
    "        x1 = self.ds_conv1(x)\n",
    "        x1 = self.norm2(x1)\n",
    "        \n",
    "        # Depthwise separable convolution with 5x5 kernel\n",
    "        x2 = self.ds_conv2(x)\n",
    "        x2 = self.norm2(x2)\n",
    "        \n",
    "        # Depthwise separable convolution with 7x7 kernel\n",
    "        x3 = self.ds_conv3(x)\n",
    "        x3 = self.norm2(x3)\n",
    "        \n",
    "        x = torch.concat((x1, x2, x3), dim = 1)\n",
    "        x = self.norm1(x)\n",
    "        x = F.leaky_relu(self.conv(x))\n",
    "        print(f\"MDSCONV END {x.shape} -------------------------------------------\")\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual Connection module\n",
    "class ResConnection(nn.Module):\n",
    "    # Define layers\n",
    "    def __init__(self):\n",
    "        super(ResConnection, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels = channels, out_channels = channels, kernel_size = 1, bias = False)\n",
    "        self.norm = nn.BatchNorm2d(num_features = channels)\n",
    "\n",
    "    # Apply layers\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.conv(x))\n",
    "        x = self.norm(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The main building block of LB-FCNN light architecture\n",
    "class LBFCNNLightBlock(nn.Module):\n",
    "    # Define layers\n",
    "    def __init__(self):\n",
    "        super(LBFCNNLightBlock, self).__init__()\n",
    "        self.mdsc = MDSConv()\n",
    "        self.rc = ResConnection()\n",
    "        self.conv = nn.Conv2d(in_channels = channels, out_channels = channels, kernel_size = 1, bias = False)\n",
    "        self.norm = nn.BatchNorm2d(num_features = channels)\n",
    "        \n",
    "    # Apply layers\n",
    "    def forward(self, x):\n",
    "        x_mdsc = self.mdsc(x)\n",
    "        x_rc = self.rc(x)\n",
    "        x = torch.add(x_mdsc, x_rc)\n",
    "        x = F.leaky_relu(self.conv(x))\n",
    "        x = self.norm(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LB-FCNN light model\n",
    "class LBFCNNLight(nn.Module):\n",
    "    # Define layers\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mdsc = MDSConv()\n",
    "        self.lbfcnn_block = LBFCNNLightBlock()\n",
    "        self.pool = nn.Conv2d(in_channels = channels, out_channels = channels, \n",
    "                              kernel_size = 2, stride = 2, bias = False)\n",
    "        self.fc = nn.Linear(in_features = channels, out_features = 2)\n",
    "        # TODO: Fix pool; paper says kernel size=3, but kernel=3 results in tensor shapes that don't match the paper diagram\n",
    "        # Some other value somewhere must be excess by 1\n",
    "        \n",
    "        # TODO: Fix feature maps here don't match feature maps in paper diagram\n",
    "        \n",
    "    # Apply layers\n",
    "    def forward(self, x):\n",
    "        x = self.mdsc(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.lbfcnn_block(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.lbfcnn_block(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.lbfcnn_block(x)\n",
    "        x = self.pool(x)\n",
    "        x = F.adaptive_avg_pool2d(x, (1, 1))\n",
    "        x = torch.flatten(input = x, start_dim = 1)\n",
    "        x = self.fc(x)\n",
    "        x = F.softmax(input = x, dim = 1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from PyTorch source code for MobileNetv2\n",
    "# source: https://github.com/pytorch/vision/blob/main/torchvision/models/mobilenetv2.py#L67\n",
    "class InvertedResidual(nn.Module):\n",
    "    def __init__(\n",
    "        self, inp: int, oup: int, stride: int, expand_ratio: int, norm_layer: Optional[Callable[..., nn.Module]] = None\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.stride = stride\n",
    "        if stride not in [1, 2]:\n",
    "            raise ValueError(f\"stride should be 1 or 2 instead of {stride}\")\n",
    "\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "\n",
    "        # Ignore expansion factors - never used\n",
    "        hidden_dim = int(round(inp * expand_ratio))\n",
    "        self.use_res_connect = self.stride == 1 and inp == oup\n",
    "\n",
    "        layers: List[nn.Module] = []\n",
    "        if expand_ratio != 1:\n",
    "            # pw\n",
    "            layers.append(\n",
    "                # Replace Conv2dNormActivation with MDSConv()\n",
    "                # Conv2dNormActivation(inp, hidden_dim, kernel_size=1, norm_layer=norm_layer, activation_layer=nn.ReLU6)\n",
    "                MDSConv()\n",
    "            )\n",
    "        layers.extend(\n",
    "            [\n",
    "                # dw\n",
    "                MDSConv(stride=stride),\n",
    "                # Replace Conv2dNormActivation with MDSConv()\n",
    "                # Conv2dNormActivation(\n",
    "                #    hidden_dim,\n",
    "                #    hidden_dim,\n",
    "                #    stride=stride,\n",
    "                #    groups=hidden_dim,\n",
    "                #    norm_layer=norm_layer,\n",
    "                #    activation_layer=nn.ReLU6,\n",
    "                #),\n",
    "                \n",
    "                # pw-linear\n",
    "                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
    "                norm_layer(oup),\n",
    "            ]\n",
    "        )\n",
    "        self.conv = nn.Sequential(*layers)\n",
    "        self.out_channels = oup\n",
    "        self._is_cn = stride > 1\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        if self.use_res_connect:\n",
    "            return x + self.conv(x)\n",
    "        else:\n",
    "            return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from PyTorch source code for MobileNetv2\n",
    "# source: https://github.com/pytorch/vision/blob/main/torchvision/models/mobilenetv2.py#L67\n",
    "class MobileNetV2(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_classes: int = 2,\n",
    "        width_mult: float = 1.0,\n",
    "        inverted_residual_setting: Optional[List[List[int]]] = None,\n",
    "        round_nearest: int = 8,\n",
    "        block: Optional[Callable[..., nn.Module]] = None,\n",
    "        norm_layer: Optional[Callable[..., nn.Module]] = None,\n",
    "        dropout: float = 0.2,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        MobileNet V2 main class\n",
    "\n",
    "        Args:\n",
    "            num_classes (int): Number of classes\n",
    "            width_mult (float): Width multiplier - adjusts number of channels in each layer by this amount\n",
    "            inverted_residual_setting: Network structure\n",
    "            round_nearest (int): Round the number of channels in each layer to be a multiple of this number\n",
    "            Set to 1 to turn off rounding\n",
    "            block: Module specifying inverted residual building block for mobilenet\n",
    "            norm_layer: Module specifying the normalization layer to use\n",
    "            dropout (float): The droupout probability\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        if block is None:\n",
    "            block = InvertedResidual\n",
    "\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "\n",
    "        input_channel = 32\n",
    "        last_channel = 1280\n",
    "\n",
    "        if inverted_residual_setting is None:\n",
    "            inverted_residual_setting = [\n",
    "                # Expansion factor is always 1 - expansion is never done\n",
    "                \n",
    "                # t, c, n, s\n",
    "                [1, channels, 1, 1],\n",
    "                [1, channels, 2, 2],\n",
    "                [1, channels, 3, 2],\n",
    "                [1, channels, 4, 2],\n",
    "                [1, channels, 3, 1],\n",
    "                [1, channels, 3, 2],\n",
    "                [1, channels, 1, 1],\n",
    "            ]\n",
    "\n",
    "        # only check the first element, assuming user knows t,c,n,s are required\n",
    "        if len(inverted_residual_setting) == 0 or len(inverted_residual_setting[0]) != 4:\n",
    "            raise ValueError(\n",
    "                f\"inverted_residual_setting should be non-empty or a 4-element list, got {inverted_residual_setting}\"\n",
    "            )\n",
    "\n",
    "        # building first layer\n",
    "        input_channel = _make_divisible(input_channel * width_mult, round_nearest)\n",
    "        self.last_channel = _make_divisible(last_channel * max(1.0, width_mult), round_nearest)\n",
    "        features: List[nn.Module] = [\n",
    "            MDSConv()\n",
    "            # Conv2dNormActivation(3, input_channel, stride=2, norm_layer=norm_layer, activation_layer=nn.ReLU6)\n",
    "        ]\n",
    "            \n",
    "        # building inverted residual blocks\n",
    "        for t, c, n, s in inverted_residual_setting:\n",
    "            output_channel = _make_divisible(c * width_mult, round_nearest)\n",
    "            print(f\"Input: {input_channel} Output: {output_channel}\")\n",
    "            for i in range(n):\n",
    "                stride = s if i == 0 else 1\n",
    "                features.append(block(input_channel, output_channel, stride, expand_ratio=t, norm_layer=norm_layer))\n",
    "                input_channel = output_channel\n",
    "                \n",
    "        # ignore building last several layers\n",
    "        # features.append(\n",
    "            # Conv2dNormActivation(\n",
    "            #     input_channel, self.last_channel, kernel_size=1, norm_layer=norm_layer, activation_layer=nn.ReLU6\n",
    "            # )\n",
    "        # )\n",
    "        \n",
    "        # make it nn.Sequential\n",
    "        self.features = nn.Sequential(*features)\n",
    "        \n",
    "        print(self.features)\n",
    "\n",
    "        # building classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(self.last_channel, num_classes),\n",
    "            nn.Softmax(dim = 1)\n",
    "        )\n",
    "\n",
    "        # weight initialization\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\")\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.ones_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def _forward_impl(self, x: Tensor) -> Tensor:\n",
    "        # This exists since TorchScript doesn't support inheritance, so the superclass method\n",
    "        # (this one) needs to have a name other than `forward` that can be accessed in a subclass\n",
    "        x = self.features(x)\n",
    "        # Cannot use \"squeeze\" as batch-size can be 1\n",
    "        x = nn.functional.adaptive_avg_pool2d(x, (1, 1))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self._forward_impl(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing torch operations on cpu device\n"
     ]
    }
   ],
   "source": [
    "# Allocate tensors to the device used for computation\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Performing torch operations on {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 32 Output: 8\n",
      "Input: 8 Output: 8\n",
      "Input: 8 Output: 8\n",
      "Input: 8 Output: 8\n",
      "Input: 8 Output: 8\n",
      "Input: 8 Output: 8\n",
      "Input: 8 Output: 8\n",
      "Sequential(\n",
      "  (0): MDSConv(\n",
      "    (conv): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (norm2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (ds_conv1): DSConv(\n",
      "      (depthwise_conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=3, bias=False)\n",
      "      (pointwise_conv): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (ds_conv2): DSConv(\n",
      "      (depthwise_conv): Conv2d(3, 3, kernel_size=(5, 5), stride=(1, 1), padding=same, groups=3, bias=False)\n",
      "      (pointwise_conv): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (ds_conv3): DSConv(\n",
      "      (depthwise_conv): Conv2d(3, 3, kernel_size=(7, 7), stride=(1, 1), padding=same, groups=3, bias=False)\n",
      "      (pointwise_conv): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (1): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): MDSConv(\n",
      "        (conv): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (norm2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ds_conv1): DSConv(\n",
      "          (depthwise_conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=3, bias=False)\n",
      "          (pointwise_conv): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (ds_conv2): DSConv(\n",
      "          (depthwise_conv): Conv2d(3, 3, kernel_size=(5, 5), stride=(1, 1), padding=same, groups=3, bias=False)\n",
      "          (pointwise_conv): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (ds_conv3): DSConv(\n",
      "          (depthwise_conv): Conv2d(3, 3, kernel_size=(7, 7), stride=(1, 1), padding=same, groups=3, bias=False)\n",
      "          (pointwise_conv): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (2): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): MDSConv(\n",
      "        (conv): Conv2d(3, 3, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (norm1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (norm2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ds_conv1): DSConv(\n",
      "          (depthwise_conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=3, bias=False)\n",
      "          (pointwise_conv): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (ds_conv2): DSConv(\n",
      "          (depthwise_conv): Conv2d(3, 3, kernel_size=(5, 5), stride=(1, 1), padding=same, groups=3, bias=False)\n",
      "          (pointwise_conv): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (ds_conv3): DSConv(\n",
      "          (depthwise_conv): Conv2d(3, 3, kernel_size=(7, 7), stride=(1, 1), padding=same, groups=3, bias=False)\n",
      "          (pointwise_conv): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (1): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (3): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): MDSConv(\n",
      "        (conv): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (norm2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ds_conv1): DSConv(\n",
      "          (depthwise_conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=3, bias=False)\n",
      "          (pointwise_conv): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (ds_conv2): DSConv(\n",
      "          (depthwise_conv): Conv2d(3, 3, kernel_size=(5, 5), stride=(1, 1), padding=same, groups=3, bias=False)\n",
      "          (pointwise_conv): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (ds_conv3): DSConv(\n",
      "          (depthwise_conv): Conv2d(3, 3, kernel_size=(7, 7), stride=(1, 1), padding=same, groups=3, bias=False)\n",
      "          (pointwise_conv): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (1): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (4): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): MDSConv(\n",
      "        (conv): Conv2d(3, 3, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (norm1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (norm2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ds_conv1): DSConv(\n",
      "          (depthwise_conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=3, bias=False)\n",
      "          (pointwise_conv): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (ds_conv2): DSConv(\n",
      "          (depthwise_conv): Conv2d(3, 3, kernel_size=(5, 5), stride=(1, 1), padding=same, groups=3, bias=False)\n",
      "          (pointwise_conv): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (ds_conv3): DSConv(\n",
      "          (depthwise_conv): Conv2d(3, 3, kernel_size=(7, 7), stride=(1, 1), padding=same, groups=3, bias=False)\n",
      "          (pointwise_conv): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (1): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (5): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): MDSConv(\n",
      "        (conv): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (norm2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ds_conv1): DSConv(\n",
      "          (depthwise_conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=3, bias=False)\n",
      "          (pointwise_conv): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (ds_conv2): DSConv(\n",
      "          (depthwise_conv): Conv2d(3, 3, kernel_size=(5, 5), stride=(1, 1), padding=same, groups=3, bias=False)\n",
      "          (pointwise_conv): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (ds_conv3): DSConv(\n",
      "          (depthwise_conv): Conv2d(3, 3, kernel_size=(7, 7), stride=(1, 1), padding=same, groups=3, bias=False)\n",
      "          (pointwise_conv): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (1): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (6): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): MDSConv(\n",
      "        (conv): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (norm2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ds_conv1): DSConv(\n",
      "          (depthwise_conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=3, bias=False)\n",
      "          (pointwise_conv): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (ds_conv2): DSConv(\n",
      "          (depthwise_conv): Conv2d(3, 3, kernel_size=(5, 5), stride=(1, 1), padding=same, groups=3, bias=False)\n",
      "          (pointwise_conv): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (ds_conv3): DSConv(\n",
      "          (depthwise_conv): Conv2d(3, 3, kernel_size=(7, 7), stride=(1, 1), padding=same, groups=3, bias=False)\n",
      "          (pointwise_conv): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (1): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (7): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): MDSConv(\n",
      "        (conv): Conv2d(3, 3, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (norm1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (norm2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ds_conv1): DSConv(\n",
      "          (depthwise_conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=3, bias=False)\n",
      "          (pointwise_conv): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (ds_conv2): DSConv(\n",
      "          (depthwise_conv): Conv2d(3, 3, kernel_size=(5, 5), stride=(1, 1), padding=same, groups=3, bias=False)\n",
      "          (pointwise_conv): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (ds_conv3): DSConv(\n",
      "          (depthwise_conv): Conv2d(3, 3, kernel_size=(7, 7), stride=(1, 1), padding=same, groups=3, bias=False)\n",
      "          (pointwise_conv): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (1): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (8): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): MDSConv(\n",
      "        (conv): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (norm2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ds_conv1): DSConv(\n",
      "          (depthwise_conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=3, bias=False)\n",
      "          (pointwise_conv): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (ds_conv2): DSConv(\n",
      "          (depthwise_conv): Conv2d(3, 3, kernel_size=(5, 5), stride=(1, 1), padding=same, groups=3, bias=False)\n",
      "          (pointwise_conv): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (ds_conv3): DSConv(\n",
      "          (depthwise_conv): Conv2d(3, 3, kernel_size=(7, 7), stride=(1, 1), padding=same, groups=3, bias=False)\n",
      "          (pointwise_conv): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (1): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (9): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): MDSConv(\n",
      "        (conv): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (norm2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ds_conv1): DSConv(\n",
      "          (depthwise_conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=3, bias=False)\n",
      "          (pointwise_conv): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (ds_conv2): DSConv(\n",
      "          (depthwise_conv): Conv2d(3, 3, kernel_size=(5, 5), stride=(1, 1), padding=same, groups=3, bias=False)\n",
      "          (pointwise_conv): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (ds_conv3): DSConv(\n",
      "          (depthwise_conv): Conv2d(3, 3, kernel_size=(7, 7), stride=(1, 1), padding=same, groups=3, bias=False)\n",
      "          (pointwise_conv): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (1): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (10): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): MDSConv(\n",
      "        (conv): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (norm2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ds_conv1): DSConv(\n",
      "          (depthwise_conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=3, bias=False)\n",
      "          (pointwise_conv): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (ds_conv2): DSConv(\n",
      "          (depthwise_conv): Conv2d(3, 3, kernel_size=(5, 5), stride=(1, 1), padding=same, groups=3, bias=False)\n",
      "          (pointwise_conv): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (ds_conv3): DSConv(\n",
      "          (depthwise_conv): Conv2d(3, 3, kernel_size=(7, 7), stride=(1, 1), padding=same, groups=3, bias=False)\n",
      "          (pointwise_conv): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (1): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (11): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): MDSConv(\n",
      "        (conv): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (norm2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ds_conv1): DSConv(\n",
      "          (depthwise_conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=3, bias=False)\n",
      "          (pointwise_conv): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (ds_conv2): DSConv(\n",
      "          (depthwise_conv): Conv2d(3, 3, kernel_size=(5, 5), stride=(1, 1), padding=same, groups=3, bias=False)\n",
      "          (pointwise_conv): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (ds_conv3): DSConv(\n",
      "          (depthwise_conv): Conv2d(3, 3, kernel_size=(7, 7), stride=(1, 1), padding=same, groups=3, bias=False)\n",
      "          (pointwise_conv): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (1): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (12): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): MDSConv(\n",
      "        (conv): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (norm2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ds_conv1): DSConv(\n",
      "          (depthwise_conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=3, bias=False)\n",
      "          (pointwise_conv): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (ds_conv2): DSConv(\n",
      "          (depthwise_conv): Conv2d(3, 3, kernel_size=(5, 5), stride=(1, 1), padding=same, groups=3, bias=False)\n",
      "          (pointwise_conv): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (ds_conv3): DSConv(\n",
      "          (depthwise_conv): Conv2d(3, 3, kernel_size=(7, 7), stride=(1, 1), padding=same, groups=3, bias=False)\n",
      "          (pointwise_conv): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (1): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (13): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): MDSConv(\n",
      "        (conv): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (norm2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ds_conv1): DSConv(\n",
      "          (depthwise_conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=3, bias=False)\n",
      "          (pointwise_conv): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (ds_conv2): DSConv(\n",
      "          (depthwise_conv): Conv2d(3, 3, kernel_size=(5, 5), stride=(1, 1), padding=same, groups=3, bias=False)\n",
      "          (pointwise_conv): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (ds_conv3): DSConv(\n",
      "          (depthwise_conv): Conv2d(3, 3, kernel_size=(7, 7), stride=(1, 1), padding=same, groups=3, bias=False)\n",
      "          (pointwise_conv): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (1): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (14): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): MDSConv(\n",
      "        (conv): Conv2d(3, 3, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (norm1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (norm2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ds_conv1): DSConv(\n",
      "          (depthwise_conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=3, bias=False)\n",
      "          (pointwise_conv): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (ds_conv2): DSConv(\n",
      "          (depthwise_conv): Conv2d(3, 3, kernel_size=(5, 5), stride=(1, 1), padding=same, groups=3, bias=False)\n",
      "          (pointwise_conv): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (ds_conv3): DSConv(\n",
      "          (depthwise_conv): Conv2d(3, 3, kernel_size=(7, 7), stride=(1, 1), padding=same, groups=3, bias=False)\n",
      "          (pointwise_conv): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (1): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (15): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): MDSConv(\n",
      "        (conv): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (norm2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ds_conv1): DSConv(\n",
      "          (depthwise_conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=3, bias=False)\n",
      "          (pointwise_conv): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (ds_conv2): DSConv(\n",
      "          (depthwise_conv): Conv2d(3, 3, kernel_size=(5, 5), stride=(1, 1), padding=same, groups=3, bias=False)\n",
      "          (pointwise_conv): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (ds_conv3): DSConv(\n",
      "          (depthwise_conv): Conv2d(3, 3, kernel_size=(7, 7), stride=(1, 1), padding=same, groups=3, bias=False)\n",
      "          (pointwise_conv): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (1): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (16): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): MDSConv(\n",
      "        (conv): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (norm2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ds_conv1): DSConv(\n",
      "          (depthwise_conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=3, bias=False)\n",
      "          (pointwise_conv): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (ds_conv2): DSConv(\n",
      "          (depthwise_conv): Conv2d(3, 3, kernel_size=(5, 5), stride=(1, 1), padding=same, groups=3, bias=False)\n",
      "          (pointwise_conv): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (ds_conv3): DSConv(\n",
      "          (depthwise_conv): Conv2d(3, 3, kernel_size=(7, 7), stride=(1, 1), padding=same, groups=3, bias=False)\n",
      "          (pointwise_conv): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (1): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (17): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): MDSConv(\n",
      "        (conv): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (norm2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ds_conv1): DSConv(\n",
      "          (depthwise_conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=3, bias=False)\n",
      "          (pointwise_conv): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (ds_conv2): DSConv(\n",
      "          (depthwise_conv): Conv2d(3, 3, kernel_size=(5, 5), stride=(1, 1), padding=same, groups=3, bias=False)\n",
      "          (pointwise_conv): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (ds_conv3): DSConv(\n",
      "          (depthwise_conv): Conv2d(3, 3, kernel_size=(7, 7), stride=(1, 1), padding=same, groups=3, bias=False)\n",
      "          (pointwise_conv): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (1): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "MDSCONV START torch.Size([2, 3, 646, 220]) -------------------------------------------\n",
      "MDSCONV END torch.Size([2, 3, 646, 220]) -------------------------------------------\n",
      "MDSCONV START torch.Size([2, 3, 646, 220]) -------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MDSCONV END torch.Size([2, 3, 646, 220]) -------------------------------------------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [8, 32, 1, 1], expected input[2, 3, 646, 220] to have 32 channels, but got 3 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Inspect model shapes per layer\u001b[39;00m\n\u001b[0;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m MobileNetV2()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m----> 3\u001b[0m \u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m646\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m220\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\conv_env\\lib\\site-packages\\torchsummary\\torchsummary.py:72\u001b[0m, in \u001b[0;36msummary\u001b[1;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[0;32m     68\u001b[0m model\u001b[38;5;241m.\u001b[39mapply(register_hook)\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# make a forward pass\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# print(x.shape)\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# remove these hooks\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m hooks:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\conv_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[16], line 119\u001b[0m, in \u001b[0;36mMobileNetV2.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[16], line 111\u001b[0m, in \u001b[0;36mMobileNetV2._forward_impl\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;66;03m# This exists since TorchScript doesn't support inheritance, so the superclass method\u001b[39;00m\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;66;03m# (this one) needs to have a name other than `forward` that can be accessed in a subclass\u001b[39;00m\n\u001b[1;32m--> 111\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;66;03m# Cannot use \"squeeze\" as batch-size can be 1\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     x \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39madaptive_avg_pool2d(x, (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\conv_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\conv_env\\lib\\site-packages\\torch\\nn\\modules\\container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 204\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\conv_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1212\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1209\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mBackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks)\n\u001b[0;32m   1210\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m-> 1212\u001b[0m result \u001b[38;5;241m=\u001b[39m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[0;32m   1214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n",
      "Cell \u001b[1;32mIn[15], line 54\u001b[0m, in \u001b[0;36mInvertedResidual.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv(x)\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\conv_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\conv_env\\lib\\site-packages\\torch\\nn\\modules\\container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 204\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\conv_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1212\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1209\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mBackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks)\n\u001b[0;32m   1210\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m-> 1212\u001b[0m result \u001b[38;5;241m=\u001b[39m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[0;32m   1214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\conv_env\\lib\\site-packages\\torch\\nn\\modules\\conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\conv_env\\lib\\site-packages\\torch\\nn\\modules\\conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    457\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    458\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [8, 32, 1, 1], expected input[2, 3, 646, 220] to have 32 channels, but got 3 channels instead"
     ]
    }
   ],
   "source": [
    "# Inspect model shapes per layer\n",
    "model = MobileNetV2().to(device)\n",
    "summary(model, (3, 646, 220))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation metrics\n",
    "results_accuracy = []\n",
    "results_precision = []\n",
    "results_sensitivity = []\n",
    "results_specificity = []\n",
    "results_f1 = []\n",
    "train_losses = []\n",
    "test_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=k_folds, shuffle=True, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model for k folds, with e epochs each\n",
    "# TODO: Implement \"On each fold we utilized the early-stopping technique\n",
    "# where a small subset of the training fold was utilized as a validation dataset.\"\n",
    "for fold, (train_indices, test_indices) in enumerate(kfold.split(dataset)):\n",
    "    print('-' * 50)\n",
    "    print(f'FOLD {fold+1}/{k_folds}:')\n",
    "    print('-' * 50)\n",
    "    \n",
    "    # Sample elements randomly from selected train/test indices\n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_indices)\n",
    "    test_subsampler = torch.utils.data.SubsetRandomSampler(test_indices)\n",
    "    \n",
    "    # Get DataLoaders for training and test sets\n",
    "    trainloader = torch.utils.data.DataLoader(dataset, \n",
    "                                              batch_size=batch_size, \n",
    "                                              sampler=train_subsampler)\n",
    "    \n",
    "    testloader = torch.utils.data.DataLoader(dataset,\n",
    "                                             batch_size=batch_size, \n",
    "                                             sampler=test_subsampler)\n",
    "    \n",
    "    train_losses.append([])\n",
    "    test_losses.append([])\n",
    "    \n",
    "    # Instantiate model\n",
    "    model = MobileNetV2().to(device)\n",
    "    \n",
    "    # Define criterion (function used to compute loss) and optimizer for model\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # ---------- Run for x epochs on training set and test set ----------\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        for phase in ['train', 'test']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "                dataloader = trainloader\n",
    "            else:\n",
    "                model.eval()\n",
    "                dataloader = testloader\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            total_batch_count = 0\n",
    "\n",
    "            for inputs, labels in dataloader:\n",
    "                # Get the inputs; data is a list of [images, labels]\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    # Backpropagation\n",
    "                    optimizer.zero_grad() # Reset gradients from previous passes\n",
    "                    loss.backward() # Compute gradients using derivative of loss\n",
    "                    optimizer.step() # Update values using gradients\n",
    "                \n",
    "                total_batch_count += 1 # Increment number of finished batches\n",
    "                running_loss += loss.item() # Add batch loss to current epoch loss\n",
    "\n",
    "            running_loss /= total_batch_count\n",
    "            \n",
    "            if phase == 'train':\n",
    "                train_losses[fold].append(running_loss)\n",
    "                print(f\"Epoch {epoch+1}/{epochs} Training Loss: {running_loss}\")\n",
    "            else:\n",
    "                test_losses[fold].append(running_loss)\n",
    "                print(f\"Epoch {epoch+1}/{epochs} Test Loss: {running_loss}\")\n",
    "                  \n",
    "    # ---------- Get performance metrics for this fold ----------\n",
    "    print('-' * 50)\n",
    "    print(f'FOLD {fold+1}/{k_folds}: Test Results')\n",
    "    print('-' * 50)\n",
    "\n",
    "    true_pos = 0\n",
    "    true_neg = 0\n",
    "    false_pos = 0\n",
    "    false_neg = 0\n",
    "    total = 0\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_index, batch_data in enumerate(testloader):\n",
    "            # Get the inputs; data is a list of [images, labels]\n",
    "            images, labels = batch_data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            predictions = model(images)\n",
    "\n",
    "            # Set total and correct\n",
    "            _, predicted = torch.max(input=predictions, dim=1) # Get list of predicted classes\n",
    "            \n",
    "            # Get how many classes there were in this batch\n",
    "            total += labels.size(0)\n",
    "            \n",
    "            # Get true positive, true negative, false positive, and false negative counts\n",
    "            for index in range(len(labels)):\n",
    "                true_pos = true_pos+1 if (predicted[index] == 1 and labels[index] == 1) else true_pos\n",
    "                true_neg = true_neg+1 if (predicted[index] == 0 and labels[index] == 0) else true_neg\n",
    "                false_pos = false_pos+1 if (predicted[index] == 1 and labels[index] == 0) else false_pos\n",
    "                false_neg = false_neg+1 if (predicted[index] == 0 and labels[index] == 1) else false_neg\n",
    "    \n",
    "    print(f\"TP: {true_pos}, TN: {true_neg}, FP: {false_pos}, FN: {false_neg}, total: {total}\")\n",
    "    \n",
    "    # Get evaluation metrics\n",
    "    # accuracy: (tp + tn) / (p + n)\n",
    "    accuracy = (true_pos + true_neg)/total if total != 0 else 0\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    results_accuracy.append(accuracy)\n",
    "    \n",
    "    # precision tp / (tp + fp)\n",
    "    precision = true_pos/(true_pos + false_pos) if (true_pos + false_pos) != 0 else 0\n",
    "    print(f\"Precision: {precision}\")\n",
    "    results_precision.append(precision)\n",
    "    \n",
    "    # sensitivity: tp / (tp + fn)\n",
    "    sensitivity = true_pos/(true_pos + false_neg) if (true_pos + false_neg) != 0 else 0\n",
    "    print(f\"Sensitivity: {sensitivity}\")\n",
    "    results_sensitivity.append(sensitivity)\n",
    "    \n",
    "    # specificity: tn / (tn + fp)\n",
    "    specificity = true_neg/(true_neg + false_pos) if (true_neg + false_pos) != 0 else 0\n",
    "    print(f\"Specificity: {specificity}\")\n",
    "    results_specificity.append(specificity)\n",
    "    \n",
    "    # f1: 2(precision * recall)/(precision + recall)\n",
    "    f1 = 2 * (precision * sensitivity)/(precision + sensitivity) if (precision + sensitivity) != 0 else 0\n",
    "    print(f\"F1: {f1}\")\n",
    "    results_f1.append(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print tensor sizes per layer in model\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print optimizer's state_dict\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot train losses\n",
    "ax = plt.axes()\n",
    "for fold_losses in train_losses:\n",
    "    plt.plot(fold_losses)\n",
    "plt.title('Training Loss Evaluation per fold')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Magnitude')\n",
    "plt.legend(['Fold ' + str(x) for x in range(1, 11)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot test losses\n",
    "ax = plt.axes()\n",
    "for fold_losses in test_losses:\n",
    "    plt.plot(fold_losses)\n",
    "plt.title('Test Loss Evaluation per fold')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Magnitude')\n",
    "plt.legend(['Fold ' + str(x) for x in range(1, 11)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get performance metrics by calculcating average of metrics across all folds\n",
    "print(\"Final Performance Metrics\")\n",
    "print(f\"Accuracy: {np.mean(results_accuracy)}\")\n",
    "print(f\"Precision: {np.mean(results_precision)}\")\n",
    "print(f\"Sensitivity: {np.mean(results_sensitivity)}\")\n",
    "print(f\"Specificity: {np.mean(results_specificity)}\")\n",
    "print(f\"F1: {np.mean(results_f1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Predictions on Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_img_names = [\"0000-0-A.tif\", \"0163-0-P.tif\", \"0198-0-A.tif\"]\n",
    "sample_img_paths = [(data_dir + \"/\" + sample_img_names[i]) for i in range(len(sample_img_names))]\n",
    "sample_classes = [sample_img_names[i][5] for i in range(len(sample_img_names))]\n",
    "sample_ground_truths = [\"No Metastasis\" if sample_classes[i] == 0 else \"Metastasis\" for i in range(len(sample_img_names))]\n",
    "sample_imgs = [Image.open(img_path).convert('RGB') for img_path in sample_img_paths]\n",
    "sample_imgs_show = [Image.open(img_path) for img_path in sample_img_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_batch = torch.stack([preprocess(img).to(device) for img in sample_imgs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_preds= model(validation_batch).detach().cpu().data.numpy()\n",
    "sample_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, len(sample_imgs_show), figsize=(20, 5))\n",
    "for i, img in enumerate(sample_imgs_show):\n",
    "    ax = axs[i]\n",
    "    ax.axis('off')\n",
    "    ax.set_title(\"Prediction: {:.0f}% No Metastasis, {:.0f}% Metastasis \\n Ground Truth: {}\"\n",
    "                 .format(100*sample_preds[i,0], 100*sample_preds[i,1], sample_ground_truths[i]))\n",
    "    ax.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# NOTE: Due to lack of library support for CUDA, this will error if using CUDA\n",
    "# Get computational complexity\n",
    "model = model.to(\"cpu\")\n",
    "stat(model, (3, 646, 220))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
